@article{Zhou2014,
 abstract = {Learning sparse structures in high dimensions defines a combinatorial selection problem of e.g. informative feature dimensions and a subsequent estimation task to determine adequate model parameters. The arguably simplest sparse inference problem requires estimating a sparse mean in high dimensions when most dimensions should be discarded. We reduce sparse mean estimation to a pure selection problem by restricting the source to binary values that are contaminated with various noise models. The model selection principle of Approximation Set Coding is rigorously applied, and generalization capacity is used to evaluate different algorithms. Simulation results demonstrate the effectiveness of generalization capacity compared to traditional model selection approaches. Sampling-based approximation yields insights into the behavior of algorithms in high dimensions at different noise levels.},
 author = {Zhou, Guangyao and Geman, Stuart and Buhmann, Joachim M},
 doi = {10.1109/ISIT.2014.6874968},
 isbn = {9781479951864},
 journal = {IEEE International Symposium on Information Theory (ISIT), 2014},
 pages = {926--930},
 title = {Sparse Feature Selection by Information Theory},
 year = {2014}
}

